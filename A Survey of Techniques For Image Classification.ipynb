{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6fa19a",
   "metadata": {},
   "source": [
    "This is going to be a survey of various techniques implemented for the purpose of image classification of two classes. In this case we are looking at \"Bunny\" versus \"Not Bunny\". \"Not Bunny\" can we a wide category by which implementing solutions given an unbalanced dataset can be harder to understand best practices.\n",
    "\n",
    "Variables taken into consideration:\n",
    "\n",
    "<ol>\n",
    "    <li>Amount of Data</li>\n",
    "    <li>Data Partitioning</li>\n",
    "    <ol>\n",
    "        <li>50% Bunny and 50% Not Bunny</li>\n",
    "        <li>10% Bunny, and 10% of 9 other classes.</li>\n",
    "    </ol>\n",
    "    <li>Testing Layer</li>\n",
    "    <ol>\n",
    "        <li>out_relu</li>\n",
    "        <li>Conv_1_bn</li>\n",
    "        <li>block_16_project_BN</li>\n",
    "        <li>block_16_project</li>\n",
    "        <li>block_16_depthwise_relu</li>\n",
    "        <li>block_16_expand</li>\n",
    "        <li>block_15_add</li>\n",
    "    </ol>\n",
    "    <li>Data Augmentation</li>\n",
    "    <ol>\n",
    "        <li>None (Reshape if needed)</li>\n",
    "        <li>Averaging</li>\n",
    "        <li>UMAP</li>\n",
    "        <li>Eigenvectors</li>\n",
    "    </ol>\n",
    "    <li>Prediction Technique</li>\n",
    "    <ol>\n",
    "        <li>SVM (https://ieeexplore.ieee.org/document/8623118)</li>\n",
    "        <li>NN Layer</li>\n",
    "        <li>KNN</li>\n",
    "    </ol>\n",
    "    <li>Technique Hyperparameters</li>\n",
    "    <ol>\n",
    "        <li>Kernel Type (SVM)</li>\n",
    "        <li>Dropout Rate (NN)</li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079cbf1",
   "metadata": {},
   "source": [
    "<b>The following are all imports required to run the code below.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36f09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3ac0be",
   "metadata": {},
   "source": [
    "<b>The following are all functions used for the purpose of creating datasets.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902013d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (4272008591.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [1], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    def grab_datasets(path):\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# Directory extensions used for class creations\n",
    "class_dirs = [\"/Human\", \"/Nature-Background\", \"/Text\", \"/Dogs\", \"/Cats\", \"/Hamsters\", \"/Suggestively-Sexual\",\n",
    "              \"/Suggestively-Violent\", \"/Abstract-Background\", \"/Empty-Cages\", \"/Bunny-Drawings\"]\n",
    "\n",
    "# Deleting and recreating directories depending on partition\n",
    "def refresh_dirs(path, partition):\n",
    "    # Removing extra directories\n",
    "    class_dirs_plus = class_dirs.append(\"/Other-Usable\")\n",
    "    for name in class_dirs:  \n",
    "        try:\n",
    "            shutil.rmtree(str(path) + \"/Images-Using\" + str(name))\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't remove \" + str(path) + \"/Images-Using\" + str(name))\n",
    "    \n",
    "    # Making directories depending on what partitions are desired\n",
    "    if partition == \"50/50\":\n",
    "        os.mkdir(path + \"/Images-Using/Other-Usable\")\n",
    "    elif partition == \"Evenly Split\":\n",
    "        for name in class_dirs:\n",
    "            os.mkdir(str(path) + \"/Images-Using\" + str(name))\n",
    "\n",
    "# Creating images and over-sampling if need be\n",
    "def do_splits(path, partition):\n",
    "    if partition == \"50/50\":\n",
    "        for class_idx in class_dirs:\n",
    "            allFileNames = os.listdir(path + partition)\n",
    "            allFileNames = [path + partition + '/' + name for name in allFileNames]\n",
    "            other_directory = \"/Images-Using/Other-Usable\"\n",
    "\n",
    "            idx = 0\n",
    "            for name in allFileNames:\n",
    "                failed_naming = True\n",
    "                while failed_naming:\n",
    "                    try:\n",
    "                        shutil.copy(name, path + other_directory)\n",
    "                        os.rename(path + other_directory + '/' + name.rsplit('/', 1)[-1],\n",
    "                                  path + other_directory + '/' + str(class_idx) + '-' + str(idx) + name.rsplit('/', 1)[-1])\n",
    "                        failed_naming = False\n",
    "                    except:\n",
    "                        idx += 1\n",
    "                    idx += 1\n",
    "    elif partition == \"Evenly Split\":\n",
    "        # todo:\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "\n",
    "                    \n",
    "def grab_datasets(path):\n",
    "    # Size set for mobilenetv2\n",
    "    batch_size = 1\n",
    "    img_height = 160\n",
    "    img_width = 160\n",
    "    \n",
    "    # Training, validation and test sets created\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path + \"/Images-Using\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=321,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path + \"/Images-Using\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=321,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    val_batches = tf.data.experimental.cardinality(validation_ds)\n",
    "    test_ds = validation_ds.take(val_batches // 4)\n",
    "    validation_ds = validation_ds.skip(val_batches // 4)\n",
    "\n",
    "    # Setting up speedy image fetching to avoid bottlenecking\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_ds = validation_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429b4efd",
   "metadata": {},
   "source": [
    "<b>All code related to model creation.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed01e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def create_model():\n",
    "    # Slightly alter data for generalization purposes\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "      tf.keras.layers.RandomFlip('horizontal'),\n",
    "      tf.keras.layers.RandomRotation(0.2),\n",
    "    ])\n",
    "    \n",
    "    IMG_SHAPE = IMG_SIZE + (3,)\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet')\n",
    "    \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    return base_model\n",
    "\n",
    "# \n",
    "def get_activations(base_model, layer, train_ds):\n",
    "    n_rows, nx, ny, nz = base_model.get_layer(str(layer)).output_shape\n",
    "    x_train = np.empty((0, int(nx), int(ny), int(nz)), float)\n",
    "    y_train = np.empty((0), int)\n",
    "    \n",
    "    intermediate_layer_model = Model(inputs=base_model.input, outputs=base_model.get_layer(str(layer)).output)\n",
    "    \n",
    "    for image, label in train_ds:\n",
    "        \n",
    "        intermediate_output = intermediate_layer_model.predict(image)\n",
    "        x_train = np.concatenate((x_train, intermediate_output), axis=0)\n",
    "        y_train = np.concatenate((y_train, label), axis=0)\n",
    "        \n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8822cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_partitions = [\"50/50\",\"Evenly Split\"]\n",
    "data_percentages = [100]\n",
    "testing_layers = [\"out_relu\", \"Conv_1_bn\"]\n",
    "data_augmentations = [\"none\", \"averaging\", \"UMAP\"]\n",
    "prediction_techniques = [\"SVM\", \"NN\", \"KNN\"]\n",
    "\n",
    "for partition in data_partitions:\n",
    "    # Set path to file code is being ran at\n",
    "    images_path = os.getcwd()\n",
    "    # Delete files from previous experiment\n",
    "    refresh_dirs(images_path, partition)\n",
    "    # Create splits of what is considered training/testing data and how many classes are recognized\n",
    "    do_splits(images_path, partition)\n",
    "    \n",
    "    for percentage in data_percentages:\n",
    "        # Cull to data percentage\n",
    "        cull_data(percentage)\n",
    "        # Grab finish keras datasets\n",
    "        train_ds, validation_ds, test_ds = grab_datasets(images_path)\n",
    "        # Create mobilenetv2 base model\n",
    "        base_model = create_model()\n",
    "        \n",
    "        for layer in testing_layers:\n",
    "            # Getting model activations to train from\n",
    "            x_train, y_train = get_activations(base_model, layer, train_ds)\n",
    "            \n",
    "            for augmentation in data_augmentations:\n",
    "                #\n",
    "                n_rows, nx, ny, nz = x_train.shape\n",
    "                x_train = x_train.reshape((n_rows,nx*ny*nz))\n",
    "                x_train = np.nan_to_num(x_train, nan=0)\n",
    "\n",
    "                for technique in prediction_techniques:\n",
    "                    clf = make_pipeline(StandardScaler(), SVC(gamma=\"auto\"))\n",
    "                    clf.fit(x_train, y_train)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
