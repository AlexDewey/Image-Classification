{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a6fa19a",
   "metadata": {},
   "source": [
    "This is going to be a survey of various techniques implemented for the purpose of image classification of two classes. In this case we are looking at \"Bunny\" versus \"Not Bunny\". \"Not Bunny\" can we a wide category by which implementing solutions given an unbalanced dataset can be harder to understand best practices.\n",
    "\n",
    "Variables taken into consideration:\n",
    "\n",
    "<ol>\n",
    "    <li>Amount of Data</li>\n",
    "    <li>Data Partitioning</li>\n",
    "    <ol>\n",
    "        <li>50% Bunny and 50% Not Bunny</li>\n",
    "        <li>10% Bunny, and 10% of 9 other classes.</li>\n",
    "    </ol>\n",
    "    <li>Testing Layer</li>\n",
    "    <ol>\n",
    "        <li>out_relu</li>\n",
    "        <li>Conv_1_bn</li>\n",
    "        <li>block_16_project_BN</li>\n",
    "        <li>block_16_project</li>\n",
    "        <li>block_16_depthwise_relu</li>\n",
    "        <li>block_16_expand</li>\n",
    "        <li>block_15_add</li>\n",
    "    </ol>\n",
    "    <li>Data Augmentation</li>\n",
    "    <ol>\n",
    "        <li>None (Reshape if needed)</li>\n",
    "        <li>Averaging</li>\n",
    "        <li>UMAP</li>\n",
    "    </ol>\n",
    "    <li>Prediction Technique</li>\n",
    "    <ol>\n",
    "        <li>SVM (https://ieeexplore.ieee.org/document/8623118)</li>\n",
    "        <li>NN Layer</li>\n",
    "        <li>KNN</li>\n",
    "    </ol>\n",
    "    <li>Technique Hyperparameters</li>\n",
    "    <ol>\n",
    "        <li>Kernel Type (SVM)</li>\n",
    "        <li>Dropout Rate (NN)</li>\n",
    "    </ol>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85743354",
   "metadata": {},
   "source": [
    "The following are all imports required to run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36f09cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13e057a",
   "metadata": {},
   "source": [
    "The following are all functions used for the purpose of creating datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "902013d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (138375254.py, line 42)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [3], line 42\u001b[0;36m\u001b[0m\n\u001b[0;31m    elif partition = \"Evenly Split\":\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Directory extensions used for class creations\n",
    "class_dirs = [\"/Human\", \"/Nature-Background\", \"/Text\", \"/Dogs\", \"/Cats\", \"/Hamsters\", \"/Suggestively-Sexual\",\n",
    "              \"/Suggestively-Violent\", \"/Abstract-Background\", \"/Empty-Cages\", \"/Bunny-Drawings\"]\n",
    "\n",
    "# Deleting and recreating directories depending on partition\n",
    "def refresh_dirs(path, partition):\n",
    "    # Removing extra directories\n",
    "    class_dirs_plus = class_dirs.append(\"/Other-Usable\")\n",
    "    for name in class_dirs:  \n",
    "        try:\n",
    "            shutil.rmtree(str(path) + \"/Images-Using\" + str(name))\n",
    "        except Exception as e:\n",
    "            print(\"Couldn't remove \" + str(path) + \"/Images-Using\" + str(name))\n",
    "    \n",
    "    # Making directories depending on what partitions are desired\n",
    "    if partition == \"50/50\":\n",
    "        os.mkdir(path + \"/Images-Using/Other-Usable\")\n",
    "    elif partition == \"Evenly Split\":\n",
    "        for name in class_dirs:\n",
    "            os.mkdir(str(path) + \"/Images-Using\" + str(name))\n",
    "\n",
    "# Creating images and over-sampling if need be\n",
    "def do_splits(path, partition):\n",
    "    if partition == \"50/50\":\n",
    "        for class_idx in class_dirs:\n",
    "            allFileNames = os.listdir(path + partition)\n",
    "            allFileNames = [path + partition + '/' + name for name in allFileNames]\n",
    "            other_directory = \"/Images-Using/Other-Usable\"\n",
    "\n",
    "            idx = 0\n",
    "            for name in allFileNames:\n",
    "                failed_naming = True\n",
    "                while failed_naming:\n",
    "                    try:\n",
    "                        shutil.copy(name, path + other_directory)\n",
    "                        os.rename(path + other_directory + '/' + name.rsplit('/', 1)[-1],\n",
    "                                  path + other_directory + '/' + str(class_idx) + '-' + str(idx) + name.rsplit('/', 1)[-1])\n",
    "                        failed_naming = False\n",
    "                    except:\n",
    "                        idx += 1\n",
    "                    idx += 1\n",
    "    elif partition == \"Evenly Split\":\n",
    "        # todo:\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "\n",
    "                    \n",
    "def grab_datasets(path):\n",
    "    # Size set for mobilenetv2\n",
    "    batch_size = 1\n",
    "    img_height = 160\n",
    "    img_width = 160\n",
    "    \n",
    "    # Training, validation and test sets created\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path + \"/Images-Using\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=321,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path + \"/Images-Using\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=321,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    val_batches = tf.data.experimental.cardinality(validation_ds)\n",
    "    test_ds = validation_ds.take(val_batches // 4)\n",
    "    validation_ds = validation_ds.skip(val_batches // 4)\n",
    "\n",
    "    # Setting up speedy image fetching to avoid bottlenecking\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "    train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    validation_ds = validation_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8822cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_percentages = [100]\n",
    "data_partitions = [\"50/50\",\"Evenly Split\"]\n",
    "testing_layers = [\"out_relu\", \"Conv_1_bn\"]\n",
    "data_augmentations = [\"none\", \"averaging\", \"UMAP\"]\n",
    "prediction_techniques = [\"SVM\", \"NN\", \"KNN\"]\n",
    "\n",
    "for percentage in data_percentages:\n",
    "    for partition in data_partitions:\n",
    "        \n",
    "        # Set path to file code is being ran at\n",
    "        images_path = os.getcwd()\n",
    "        # Delete files from previous experiment\n",
    "        refresh_dirs(images_path, partition)\n",
    "        # Create splits of what is considered training/testing data and how many classes are recognized\n",
    "        do_splits(images_path, partition)\n",
    "        # Grab Keras datasets\n",
    "        train_ds, validation_ds, test_ds = grab_datasets(images_path)\n",
    "        \n",
    "        batch_size = 1\n",
    "        img_height = 160\n",
    "        img_width = 160\n",
    "        \n",
    "        \n",
    "        \n",
    "        for layer in testing_layers:\n",
    "            for augmentation in data_augmentations:\n",
    "                for technique in prediction_techniques:\n",
    "                    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
